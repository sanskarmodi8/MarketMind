{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "634af429",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c24e832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import torch\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback, EvalCallback\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "583c3b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41944c75",
   "metadata": {},
   "source": [
    "### Create Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f5b295",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TradingEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    Simple trading environment (long-only) using daily data.\n",
    "    Actions: 0 = Hold (no change), 1 = Buy (go to long), 2 = Sell (go to flat/cash)\n",
    "    Observation: window of last N days of features + current position (0 or 1)\n",
    "    Reward: change in portfolio value (percentage) minus transaction cost when action changes position\n",
    "    \"\"\"\n",
    "\n",
    "    metadata = {\"render_modes\": [\"human\"], \"render_fps\": 1}\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        df,                  # DataFrame with datetime index and feature columns\n",
    "        feature_cols=None,   # list of columns used as features (will be normalized per-window)\n",
    "        window_size=50,\n",
    "        transaction_cost=0.001,  # e.g., 0.1% per trade\n",
    "        initial_balance=1.0,\n",
    "        max_positions=1,     # 1 means long-only single position\n",
    "        reward_scaling=1.0,\n",
    "        deterministic=True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.df = df.copy()\n",
    "        self.feature_cols = feature_cols or [\"log_return\", \"SMA_short\", \"SMA_long\", \"volatility\"]\n",
    "        self.window_size = window_size\n",
    "        self.transaction_cost = transaction_cost\n",
    "        self.initial_balance = initial_balance\n",
    "        self.max_positions = max_positions\n",
    "        self.reward_scaling = reward_scaling\n",
    "        self.deterministic = deterministic\n",
    "\n",
    "        # derive start/end indices for episodes\n",
    "        self.start_index = self.window_size\n",
    "        self.end_index = len(self.df) - 1\n",
    "\n",
    "        # action space: discrete 3 actions\n",
    "        self.action_space = spaces.Discrete(3)\n",
    "\n",
    "        # observation: window_size x n_features flattened + position flag\n",
    "        self.n_features = len(self.feature_cols)\n",
    "        obs_len = self.window_size * self.n_features + 1\n",
    "        self.observation_space = spaces.Box(low=-np.inf, high=np.inf, shape=(obs_len,), dtype=np.float32)\n",
    "\n",
    "        # internal state\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "\n",
    "        # randomize start if not deterministic (useful for training)\n",
    "        if self.deterministic:\n",
    "            self.current_step = self.start_index\n",
    "        else:\n",
    "            self.current_step = np.random.randint(self.start_index, self.end_index - 1)\n",
    "\n",
    "        # portfolio state\n",
    "        self.position = 0  # 0 = flat, 1 = long\n",
    "        self.cash = self.initial_balance\n",
    "        self.position_price = 0.0  # entry price when long\n",
    "        self.portfolio_value = self.initial_balance\n",
    "\n",
    "        # return initial observation\n",
    "        return self._get_obs(), {}\n",
    "\n",
    "    def _get_obs(self):\n",
    "        # get the window of features ending at current_step (inclusive)\n",
    "        start = self.current_step - self.window_size + 1\n",
    "        end = self.current_step + 1\n",
    "        window = self.df.iloc[start:end][self.feature_cols].values  # shape (window_size, n_features)\n",
    "\n",
    "        # normalize features by z-score along column to make learning easier\n",
    "        # small epsilon to avoid divide-by-zero\n",
    "        mean = window.mean(axis=0)\n",
    "        std = window.std(axis=0) + 1e-9\n",
    "        norm_window = (window - mean) / std\n",
    "\n",
    "        # flatten and append current position\n",
    "        obs = np.concatenate([norm_window.flatten(), np.array([self.position], dtype=np.float32)])\n",
    "        return obs.astype(np.float32)\n",
    "\n",
    "    def step(self, action):\n",
    "        assert self.action_space.contains(action)\n",
    "        done = False\n",
    "        info = {}\n",
    "\n",
    "        prev_portfolio = self.portfolio_value\n",
    "        price = float(self.df[\"Close\"].iloc[self.current_step])\n",
    "        next_price = float(self.df[\"Close\"].iloc[self.current_step + 1])\n",
    "\n",
    "        # interpret action:\n",
    "        # 0 = hold; 1 = buy; 2 = sell (go flat)\n",
    "        prev_position = self.position\n",
    "        if action == 1 and self.position == 0:\n",
    "            # open long position using all capital -> position fraction 1.0\n",
    "            self.position = 1\n",
    "            # apply transaction cost based on trade notional (cash used to buy)\n",
    "            cost = self.transaction_cost * self.portfolio_value\n",
    "            self.position_price = price\n",
    "            self.cash = self.portfolio_value - cost  # assume fully invested after cost\n",
    "        elif action == 2 and self.position == 1:\n",
    "            # close position -> convert to cash at current price (we'll use next step price for PnL)\n",
    "            self.position = 0\n",
    "            # we compute realized PnL at next step handling below\n",
    "            # apply transaction cost when closing\n",
    "            cost = self.transaction_cost * self.portfolio_value\n",
    "            self.cash = self.portfolio_value - cost\n",
    "            self.position_price = 0.0\n",
    "        else:\n",
    "            # hold or invalid trade (e.g., buy when already long) -> no change in position\n",
    "            pass\n",
    "\n",
    "        # Compute portfolio change from current to next price\n",
    "        # If we are long during the interval, portfolio changes by return of price movement\n",
    "        # Use next_price/price - 1 for simple return\n",
    "        simple_return = (next_price - price) / price\n",
    "        if self.position == 1:\n",
    "            # invested capital grows by simple_return\n",
    "            self.portfolio_value = self.cash * (1 + simple_return)\n",
    "        else:\n",
    "            # position is flat -> portfolio == cash (cash doesn't grow)\n",
    "            self.portfolio_value = self.cash\n",
    "\n",
    "        # reward = change in portfolio value (relative) scaled\n",
    "        reward = (self.portfolio_value - prev_portfolio) / max(prev_portfolio, 1e-9)\n",
    "        reward = reward * self.reward_scaling\n",
    "\n",
    "        # advance step\n",
    "        self.current_step += 1\n",
    "        if self.current_step >= self.end_index:\n",
    "            done = True\n",
    "\n",
    "        # make obs\n",
    "        obs = self._get_obs()\n",
    "        return obs, float(reward), done, False, info  # gymnasium returns (obs, reward, done, truncated, info)\n",
    "\n",
    "    def render(self, mode=\"human\"):\n",
    "        # simple printout for debugging\n",
    "        print(f\"Step: {self.current_step}, Position: {self.position}, Portfolio: {self.portfolio_value:.6f}\")\n",
    "\n",
    "    def close(self):\n",
    "        pass\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atbvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
